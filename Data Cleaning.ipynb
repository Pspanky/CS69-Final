{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline  \n",
    "import tweepy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Authentication and setup for Tweepy\n",
    "\n",
    "consumer_key = 'aQzHCKeyTaBKwqJaaiwda4bkO'\n",
    "consumer_secret = 'JLRfDVG7k8GbbkkOZofL6Al69P2Ov1xhWRBAjFNFR4FwSKoXDj'\n",
    "access_token = '3125452793-u04kuuehiQIPh94QUelRV6RREMfOxoDBq7oznT7'\n",
    "access_token_secret = 'xcejx5JhpsvRvsWylOjXbeKyUce8AjxgsmFz54v5qdvrh'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handles = pd.read_csv('TwitterHandles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function which, given a set of tweets from Tweepy API, will write them to a csv file\n",
    "\n",
    "def write_tweets_to_csv(tweets, csvWriter, political_affiliation):\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        csvWriter.writerow([tweet.user.screen_name, tweet.full_text.encode('utf-8'), political_affiliation])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for retrieving latest tweets of a given username\n",
    "\n",
    "def get_user_tweets(username, tweet_count = 200): \n",
    "    \n",
    "    tweets = api.user_timeline(screen_name = username, count = tweet_count, \n",
    "                          include_rts = False, tweet_mode='extended')\n",
    "    return tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main function for recording tweets from an account\n",
    "\n",
    "def record_tweets(username, csvWriter, politic):\n",
    "    \n",
    "    tweets = get_user_tweets(username)\n",
    "    \n",
    "    write_tweets_to_csv(tweets, csvWriter, politic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a dataframe of politician usernames will c\n",
    "\n",
    "def get_tweets_from_dataframe(dataframe, csvWriter):\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        record_tweets(row['TwitterHandle'], csvWriter, row['Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize a csv file\n",
    "csvFile = open('tweets_final3.csv', 'a')\n",
    "\n",
    "#Use csv Writer\n",
    "csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_tweets_from_dataframe(handles, csvWriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the csv into a dataframe\n",
    "\n",
    "tweets_df = pd.read_csv('tweets_final3.csv', names = [\"username\", \"tweets_raw\", \"politics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consist mostly of processing the raw tweets to be more suitable as input features for LDA/sentiment extraction. Involves removing emoji encodings, special characters and the url to the tweet which tweepy embeds in every tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Various methods for cleaning tweet strings to make them better suited for sentiment analysis\n",
    "\n",
    "def remove_emojis(string):\n",
    "    \n",
    "    corrected = re.sub(r'\\\\x[\\w+]{2}', '', string)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "def remove_url(text):\n",
    "    \n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_apostrophes(string):\n",
    "    \n",
    "    corrected = re.sub(r'\\\\xe2\\\\x80\\\\x99', '\\'', string)\n",
    "    \n",
    "    corrected = re.sub(r'\\&amp;', 'and', string)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "def remove_byte_encoding(string):\n",
    "    return string[2:]\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    \n",
    "            \n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "        parts = tweet.split('.')\n",
    "        \n",
    "        for i in range(len(parts)):\n",
    "            parts[i] = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", parts[i])\n",
    "            \n",
    "        cleaned_tweet = \" \".join(parts)\n",
    "        \n",
    "        return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    \n",
    "    temp = remove_byte_encoding(string)\n",
    "    temp = remove_url(temp)\n",
    "    temp = correct_apostrophes(temp)\n",
    "    temp = remove_emojis(temp)\n",
    "    final = clean_tweet(temp)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dataframe_tweets(dataframe):\n",
    "    \n",
    "    new_strings = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        new_strings.append(clean_string(row['tweets_raw']))\n",
    "    \n",
    "    return new_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned = clean_dataframe_tweets(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_df['tweets_clean'] = cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiments, hashtags, and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting hashtags and adding them as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts all hashtags from a string. Useful for getting hashtags from tweets\n",
    "\n",
    "def extract_hashtags(string):\n",
    "    hashtags = re.findall(r\"#(\\w+)\", string)\n",
    "    \n",
    "    return hashtags\n",
    "\n",
    "\n",
    "# Iterates over a dataframe and extracts all hashtags\n",
    "\n",
    "def find_hashtags(dataframe):\n",
    "    \n",
    "    h_list = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        hashtags = extract_hashtags(row['tweets_raw'])\n",
    "        \n",
    "        h_list.append(hashtags)\n",
    "    \n",
    "    return h_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting mentions and adding  them as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts all hashtags from a string. Useful for getting hashtags from tweets\n",
    "\n",
    "def extract_mentions(string):\n",
    "    hashtags = re.findall(r\"@(\\w+)\", string)\n",
    "    \n",
    "    return hashtags\n",
    "\n",
    "\n",
    "# Iterates over a dataframe and extracts all hashtags\n",
    "\n",
    "def find_mentions(dataframe):\n",
    "    \n",
    "    h_list = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        hashtags = extract_mentions(row['tweets_raw'])\n",
    "        \n",
    "        h_list.append(hashtags)\n",
    "    \n",
    "    return h_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract hashtags and add them as a separate column\n",
    "\n",
    "hashtags = find_hashtags(tweets_df)\n",
    "\n",
    "tweets_df['hashtags'] = hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract mentions and add them as a separate column\n",
    "\n",
    "mentions = find_mentions(tweets_df)\n",
    "\n",
    "tweets_df['mentions'] = mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentiment(string):\n",
    "    text = TextBlob(string)\n",
    "    \n",
    "    return text.sentiment\n",
    "\n",
    "def get_dataframe_sentiments(dataframe):\n",
    "    \n",
    "    sentiments = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        sentiments.append(get_sentiment(row['tweets_clean']))\n",
    "        \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments = get_dataframe_sentiments(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_df['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df_d = tweets_df.head(n=33099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df_r = tweets_df.iloc[33099:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct corpus from the tweets, grouped by politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = tweets_df['tweets_clean']\n",
    "s.str.cat(sep='. ')\n",
    "\n",
    "corpus = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = tweets_df_d['tweets_clean']\n",
    "s.str.cat(sep='. ')\n",
    "\n",
    "corpus_d = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tweets_df_r['tweets_clean']\n",
    "\n",
    "corpus_r = s.str.cat(sep='. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PSpankay\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import string\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_clean = [clean(doc).split() for doc in tweets_df_r['tweets_clean']]  \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running and Trainign LDA model on the document term matrix\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_ldaModels(floor, ceiling):\n",
    "    \n",
    "    if floor <= ceiling:\n",
    "        \n",
    "        models = []\n",
    "        \n",
    "        i = floor\n",
    "\n",
    "        while i != ceiling:\n",
    "            models.append(Lda(doc_term_matrix, num_topics=i, id2word = dictionary, passes=2))\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_topics(ldamodel):\n",
    "    \n",
    "    topics = []\n",
    "    \n",
    "    for i in range(len(ldamodel.print_topics())):\n",
    "        \n",
    "        values = []\n",
    "        \n",
    "        topic_words = ldamodel.print_topic(i).split('+')\n",
    "        \n",
    "        for i in range(len(topic_words)):\n",
    "        \n",
    "            values.append(get_values(topic_words[i], (i==len(topic_words)-1)))\n",
    "        \n",
    "        topics.append(values)\n",
    "        \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(string, last=False):\n",
    "    \n",
    "    probability = string[0:6]\n",
    "    \n",
    "    if probability[-1] == '*':\n",
    "        probability = probability[:-1]\n",
    "        \n",
    "    probability = float(probability)\n",
    "    \n",
    "    if last:\n",
    "        word = string[7:-1]\n",
    "    else: word = string[7:-2]\n",
    "    \n",
    "    return (probability, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "en_stop = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Converting corpus to bag of words so it can be used for generating an LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "    \n",
    "    doc_clean = [clean(doc).split() for doc in corpus]  \n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    \n",
    "    return doc_term_matrix, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_new, doc = preprocess_corpus(tweets_df_d['tweets_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating actual LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_LDA_model(corpus, num_topics=10):\n",
    "    \n",
    "    new_corpus, dictionary = preprocess_corpus(corpus)\n",
    "    \n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(new_corpus, num_topics=num_topics, id2word = dictionary, passes=2)\n",
    "    \n",
    "    return ldamodel\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_to_row(dist, num_topics=10):\n",
    "    \n",
    "    row = []\n",
    "    \n",
    "    for i in range(num_topics):\n",
    "        row.append(0)\n",
    "    \n",
    "    for topic in dist:\n",
    "        row[topic[0]] = topic[1]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_topic_distribution(string, ldamodel):\n",
    "    \n",
    "    tokens = tokenizer.tokenize(string)\n",
    "    \n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    texts = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    bow = ldamodel.id2word.doc2bow(texts)\n",
    "    \n",
    "    return ldamodel.get_document_topics(bow)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_column_names1 = ['1 - topic 0', '1 - topic 1', '1 - topic 0', '1 - topic 3',\n",
    "                         '1 - topic 4', '1 - topic 5', '1 - topic 6', '1 - topic 7',\n",
    "                         '1 - topic 8', '1 - topic 9']\n",
    "\n",
    "topic_column_names2 = ['2 - topic 0', '2 - topic 1', '2- topic 0', '2- topic 3',\n",
    "                         '2 - topic 4', '2 - topic 5', '2- topic 6', '2- topic 7',\n",
    "                         '2 - topic 8', '2- topic 9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(columns=topic_column_names1 + topic_column_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_to_tdistrib(tweet, ldamodel, second=False):\n",
    "    t_distrib = get_topic_distribution(tweet, ldamodel)\n",
    "    \n",
    "    if second:\n",
    "        return pd.Series(dist_to_row(t_distrib), index = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19'])\n",
    "    \n",
    "    return pd.Series(dist_to_row(t_distrib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_features(dataframe, ldamodel1, ldamodel2):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        tweet = row['tweets_clean']\n",
    "        \n",
    "        new_row = tweet_to_row(tweet, ldamodel1, ldamodel2)\n",
    "        \n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictor using two LDA models \n",
    "#### one trained on republican tweets and one trained on democratic tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_to_row(tweet, lda1, lda2):\n",
    "    \n",
    "    t_row_1 = tweet_to_tdistrib(tweet, lda1)\n",
    "    t_row_2 = tweet_to_tdistrib(tweet, lda2, True)\n",
    "    \n",
    "    new_row = t_row_1.append(t_row_2)\n",
    "    \n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_model = generate_LDA_model(tweets_df_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_model = generate_LDA_model(tweets_df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_topics = get_topic_features(tweets_df, d_model, r_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_topics.columns = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\n",
    "           'Democrat': 0,\n",
    "           'Republican': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_sentiment(dataframe, sentiment):\n",
    "    df = dataframe.mul(sentiment, axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiments(dataframe):\n",
    "    \n",
    "    s = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        s.append(row['sentiment'][0])\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiments = get_sentiments(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_mentions(df):\n",
    "    \n",
    "    mentions = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        m = row['mentions']\n",
    "        \n",
    "        for mention in m:\n",
    "            \n",
    "            if mention not in mentions:\n",
    "                mentions[mention] = 1\n",
    "            \n",
    "            else:\n",
    "                mentions[mention] += 1\n",
    "        \n",
    "    return mentions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlist = gather_mentions(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12054"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See what the frequency of different users being mentioned is. Most  are mentioned only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf = pd.DataFrame.from_records(mlist, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf1 = mdf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       8259\n",
       "2       1654\n",
       "3        644\n",
       "4        337\n",
       "5        234\n",
       "6        150\n",
       "7         97\n",
       "8         89\n",
       "9         70\n",
       "10        63\n",
       "12        57\n",
       "11        42\n",
       "13        38\n",
       "14        36\n",
       "15        23\n",
       "16        21\n",
       "17        14\n",
       "18        13\n",
       "19        11\n",
       "28        10\n",
       "20         9\n",
       "21         9\n",
       "30         8\n",
       "23         8\n",
       "22         7\n",
       "33         7\n",
       "25         6\n",
       "24         6\n",
       "27         6\n",
       "32         5\n",
       "        ... \n",
       "53         1\n",
       "95         1\n",
       "87         1\n",
       "71         1\n",
       "47         1\n",
       "1166       1\n",
       "214        1\n",
       "86         1\n",
       "70         1\n",
       "589        1\n",
       "109        1\n",
       "93         1\n",
       "69         1\n",
       "61         1\n",
       "1180       1\n",
       "82         1\n",
       "124        1\n",
       "108        1\n",
       "76         1\n",
       "68         1\n",
       "60         1\n",
       "52         1\n",
       "151        1\n",
       "99         1\n",
       "51         1\n",
       "35         1\n",
       "202        1\n",
       "178        1\n",
       "106        1\n",
       "123        1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf1[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all users who were mentioned at least 30 times in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf2 = mdf1[mdf1[0] >= 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AIPAC</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AjitPaiFCC</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarackObama</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BetsyDeVosED</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDCgov</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "AIPAC         36\n",
       "AjitPaiFCC    43\n",
       "BarackObama   40\n",
       "BetsyDeVosED  74\n",
       "CDCgov        30"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf3 = mdf2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = mdf3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AIPAC', 'AjitPaiFCC', 'BarackObama', 'BetsyDeVosED', 'CFPB', 'CNN',\n",
       "       'CongressionalAC', 'DHSgov', 'DeptVetAffairs', 'DeptofDefense',\n",
       "       ...\n",
       "       'louiseslaughter', 'marcorubio', 'nytimes', 'realDonaldTrump',\n",
       "       'realdonaldtrump', 'repjohnlewis', 'the_USO', 'thehill', 'uscapitol',\n",
       "       'usedgov'],\n",
       "      dtype='object', length=111)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial testing and model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_d = df_topics.loc[:, '0':'9']\n",
    "topics_r = df_topics.loc[:, '10':'19']\n",
    "\n",
    "topics_d = topics_d.astype('float')\n",
    "topics_r = topics_r.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_final = apply_sentiment(topics_d, sentiments)\n",
    "r_final = apply_sentiment(topics_r, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dx = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the X and y matrices\n",
    "Here X is each tweet's probability distribution over 10 different topics, and y is the political orientation of the politician who made the tweet\n",
    "\n",
    "This is where I got my results for the initial round of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = topics_d\n",
    "y = tweets_df['politics'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5031544793606921"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentions feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIPAC</th>\n",
       "      <th>AjitPaiFCC</th>\n",
       "      <th>BarackObama</th>\n",
       "      <th>BetsyDeVosED</th>\n",
       "      <th>CDCgov</th>\n",
       "      <th>CFPB</th>\n",
       "      <th>CNN</th>\n",
       "      <th>ConawayTX11</th>\n",
       "      <th>CongressionalAC</th>\n",
       "      <th>DHSgov</th>\n",
       "      <th>...</th>\n",
       "      <th>realdonaldtrump</th>\n",
       "      <th>rep_stevewomack</th>\n",
       "      <th>repjohnlewis</th>\n",
       "      <th>the_USO</th>\n",
       "      <th>thehill</th>\n",
       "      <th>usairforce</th>\n",
       "      <th>uscapitol</th>\n",
       "      <th>usedgov</th>\n",
       "      <th>virginiafoxx</th>\n",
       "      <th>washingtonpost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIPAC  AjitPaiFCC  BarackObama  BetsyDeVosED  CDCgov  CFPB  CNN  \\\n",
       "0     36          43           40            74      30    55   68   \n",
       "\n",
       "   ConawayTX11  CongressionalAC  DHSgov       ...        realdonaldtrump  \\\n",
       "0           30               48      74       ...                    106   \n",
       "\n",
       "   rep_stevewomack  repjohnlewis  the_USO  thehill  usairforce  uscapitol  \\\n",
       "0               30            49       59       55          32         85   \n",
       "\n",
       "   usedgov  virginiafoxx  washingtonpost  \n",
       "0       47            34              33  \n",
       "\n",
       "[1 rows x 137 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentiondf = pd.DataFrame(columns=mdf3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mentions_hash = {}\n",
    "\n",
    "v = mentiondf.columns.values\n",
    "\n",
    "for i in range(len(v)):\n",
    "    mentions_hash[v[i]] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMentionVector(mentions, vlen):\n",
    "    \n",
    "    vector = [0]*vlen\n",
    "    \n",
    "    for m in mentions:\n",
    "        \n",
    "        if m in mentions_hash:\n",
    "            \n",
    "            index = mentions_hash[m]\n",
    "            vector[index] = 1\n",
    "    \n",
    "    return pd.DataFrame(pd.Series(vector, index=mdf3.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMentionVector(mentions, vlen):\n",
    "    \n",
    "    vector = [0]*vlen\n",
    "    \n",
    "    for m in mentions:\n",
    "        \n",
    "        if m in mentions_hash:\n",
    "            \n",
    "            index = mentions_hash[m]\n",
    "            vector[index] = 1\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Function for constructing mention matrix\n",
    "Feature I was thinking about but did not get to implement. The idea is building a co-occurence matrix for the usernames which were mentioned the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mentionMatrix(dataframe):\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i < dataframe.shape[0]:\n",
    "        \n",
    "        new_row = getMentionVector(dataframe['mentions'][i], len(mdf3.columns.values))\n",
    "        \n",
    "        rows.append(new_row)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    df = pd.DataFrame(rows, columns = mdf3.columns.values)\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66572, 7)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.290910984685979"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "mm = mentionMatrix(tweets_df)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "mm = mentionMatrix(tweets_df.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [AIPAC, AjitPaiFCC, BarackObama, BetsyDeVosED, CDCgov, CFPB, CNN, ConawayTX11, CongressionalAC, DHSgov, DeptVetAffairs, DeptofDefense, DrPhilRoe, ENERGY, EPA, EPAScottPruitt, EPAoig, EdWorkforce, EmmanuelMacron, EnergyCommerce, FBI, FCC, FEMA, FLOTUS, FinancialCmte, FoxBusiness, FoxNews, GOP, GOPLeader, GOPoversight, Google, HASCDemocrats, HASCRepublicans, HHSGov, HUDgov, HispanicCaucus, HouseAgNews, HouseAppropsGOP, HouseCommerce, HouseDemocrats, HouseFloor, HouseForeign, HouseGOP, HouseHomeland, HouseJudDems, HouseJudiciary, HouseScience, HouseVetAffairs, HurdOnTheHill, IngrahamAngle, Interior, MSNBC, MacTXPress, MariaBartiromo, MickMulvaneyOMB, MorningsMaria, MrsB1stGraders, NASA, NIH, NRA, NYGovCuomo, NancyPelosi, NatResources, NatlParkService, OfficialCBC, POTUS, PPFA, PeteSessions, RealDonaldTrump, RepBarbaraLee, RepCurbelo, RepEspaillat, RepGoodlatte, RepKevinBrady, RepMarcyKaptur, RepMarkMeadows, RepMarkWalker, RepMcCaul, RepTedDeutch, RosLehtinen, SBAgov, SecAzar, SecPompeo, SecretaryCarson, SecretarySonny, SecretaryZinke, SenDuckworth, SenJohnMcCain, SenSchumer, SenateDems, SenateMajLdr, SpeakerRyan, StateDept, SteveScalise, TGowdySC, TeamCavuto, TheJusticeDept, Transport, USArmy, USArmyReserve, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 137 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PSpankay\\Anaconda3\\lib\\site-packages\\pandas\\indexes\\api.py:71: RuntimeWarning: '<' not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "mn = mentionMatrix(tweets_df.iloc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mx = pd.concat(r, axis=1, keys=mdf3.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mx = apply_sentiment(mm, sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Second round of testing using the sparse mentions matrix as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = mm\n",
    "y = tweets_df['politics'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5411584449918885"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my = topics_d.join(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mys = apply_sentiment(my, sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mys\n",
    "y = tweets_df['politics'].map(mapping)\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tweets_df['username'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate tweets by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregateTweets(dataframe):\n",
    "    \n",
    "    t = []\n",
    "    \n",
    "    current = ''\n",
    "    \n",
    "    i = -1\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        if current != row['username']:\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            current = row['username']\n",
    "            \n",
    "            t.append([row['username'], row['tweets_raw'], row['tweets_clean'],  row['politics']])\n",
    "            \n",
    "    \n",
    "        else:\n",
    "            t[i][1] += \" \" + row['tweets_clean']\n",
    "    \n",
    "    \n",
    "    return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdic = aggregateTweets(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_df = pd.DataFrame(tdic, columns = ['username', 'tweets_raw', 'tweets_clean', 'politic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweets_raw</th>\n",
       "      <th>tweets_clean</th>\n",
       "      <th>politic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'Touching &amp;amp; productive conversation w/ Fl...</td>\n",
       "      <td>Touching and productive conversation w  Florid...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepJackyRosen</td>\n",
       "      <td>b\"Today, I met with the Nevada Radiological So...</td>\n",
       "      <td>Today  I met with the Nevada Radiological Soci...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepAlLawsonJr</td>\n",
       "      <td>b'Looking forward to speaking on the House Flo...</td>\n",
       "      <td>Looking forward to speaking on the House Floor...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepEspaillat</td>\n",
       "      <td>b'Photos from today\\xe2\\x80\\x99s reception in ...</td>\n",
       "      <td>Photos from todays reception in Washington DC ...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepBRochester</td>\n",
       "      <td>b'Today, I took part in a gun violence prevent...</td>\n",
       "      <td>Today  I took part in a gun violence preventio...</td>\n",
       "      <td>Democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                         tweets_raw  \\\n",
       "0  RepDarrenSoto  b'Touching &amp; productive conversation w/ Fl...   \n",
       "1  RepJackyRosen  b\"Today, I met with the Nevada Radiological So...   \n",
       "2  RepAlLawsonJr  b'Looking forward to speaking on the House Flo...   \n",
       "3   RepEspaillat  b'Photos from today\\xe2\\x80\\x99s reception in ...   \n",
       "4  RepBRochester  b'Today, I took part in a gun violence prevent...   \n",
       "\n",
       "                                        tweets_clean   politic  \n",
       "0  Touching and productive conversation w  Florid...  Democrat  \n",
       "1  Today  I met with the Nevada Radiological Soci...  Democrat  \n",
       "2  Looking forward to speaking on the House Floor...  Democrat  \n",
       "3  Photos from todays reception in Washington DC ...  Democrat  \n",
       "4  Today  I took part in a gun violence preventio...  Democrat  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newModel = generate_LDA_model(author_df['tweets_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_features1(dataframe, ldamodel):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        \n",
    "        tweet = row['tweets_clean']\n",
    "        \n",
    "        new_row = tweet_to_row1(tweet, ldamodel)\n",
    "        \n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "        \n",
    "def tweet_to_row1(tweet, lda1):\n",
    "    \n",
    "    t_row_1 = tweet_to_tdistrib(tweet, lda1)\n",
    "    \n",
    "    new_row = t_row_1\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "def tweet_to_tdistrib(tweet, ldamodel, second=False):\n",
    "    t_distrib = get_topic_distribution(tweet, ldamodel)\n",
    "    \n",
    "    if second:\n",
    "        return pd.Series(dist_to_row(t_distrib), index = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19'])\n",
    "    \n",
    "    return pd.Series(dist_to_row(t_distrib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_topics = get_topic_features1(author_df, newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.405258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.135991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338031</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.169129</td>\n",
       "      <td>0.540331</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.250519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670603</td>\n",
       "      <td>0.043834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.678088</td>\n",
       "      <td>0.082257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2         3         4         5         6         7  \\\n",
       "0  0.000000  0.0  0.0  0.330500  0.405258  0.000000  0.045051  0.082600   \n",
       "1  0.000000  0.0  0.0  0.000000  0.581370  0.000000  0.338031  0.066092   \n",
       "2  0.000000  0.0  0.0  0.017172  0.169129  0.540331  0.022605  0.250519   \n",
       "3  0.000000  0.0  0.0  0.000000  0.269903  0.000000  0.670603  0.043834   \n",
       "4  0.021923  0.0  0.0  0.016172  0.678088  0.082257  0.000000  0.180526   \n",
       "\n",
       "          8    9  \n",
       "0  0.135991  0.0  \n",
       "1  0.000000  0.0  \n",
       "2  0.000000  0.0  \n",
       "3  0.000000  0.0  \n",
       "4  0.000000  0.0  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third round of testing\n",
    "This is where I tested my model on collections of author's tweets as opposed to feeding in tweets individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = author_topics\n",
    "y = author_df['politic'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488372093023255"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 10)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_topics_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweets_raw</th>\n",
       "      <th>tweets_clean</th>\n",
       "      <th>politic</th>\n",
       "      <th>mentions</th>\n",
       "      <th>mmentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'Touching &amp;amp; productive conversation w/ Fl...</td>\n",
       "      <td>Touching and productive conversation w  Florid...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepJackyRosen</td>\n",
       "      <td>b\"Today, I met with the Nevada Radiological So...</td>\n",
       "      <td>Today  I met with the Nevada Radiological Soci...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepAlLawsonJr</td>\n",
       "      <td>b'Looking forward to speaking on the House Flo...</td>\n",
       "      <td>Looking forward to speaking on the House Floor...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepEspaillat</td>\n",
       "      <td>b'Photos from today\\xe2\\x80\\x99s reception in ...</td>\n",
       "      <td>Photos from todays reception in Washington DC ...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>[RepEspaillat]</td>\n",
       "      <td>RepEspaillat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepBRochester</td>\n",
       "      <td>b'Today, I took part in a gun violence prevent...</td>\n",
       "      <td>Today  I took part in a gun violence preventio...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                         tweets_raw  \\\n",
       "0  RepDarrenSoto  b'Touching &amp; productive conversation w/ Fl...   \n",
       "1  RepJackyRosen  b\"Today, I met with the Nevada Radiological So...   \n",
       "2  RepAlLawsonJr  b'Looking forward to speaking on the House Flo...   \n",
       "3   RepEspaillat  b'Photos from today\\xe2\\x80\\x99s reception in ...   \n",
       "4  RepBRochester  b'Today, I took part in a gun violence prevent...   \n",
       "\n",
       "                                        tweets_clean   politic  \\\n",
       "0  Touching and productive conversation w  Florid...  Democrat   \n",
       "1  Today  I met with the Nevada Radiological Soci...  Democrat   \n",
       "2  Looking forward to speaking on the House Floor...  Democrat   \n",
       "3  Photos from todays reception in Washington DC ...  Democrat   \n",
       "4  Today  I took part in a gun violence preventio...  Democrat   \n",
       "\n",
       "         mentions     mmentions  \n",
       "0              []                \n",
       "1              []                \n",
       "2              []                \n",
       "3  [RepEspaillat]  RepEspaillat  \n",
       "4              []                "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_df_d = author_df.loc[author_df['politic']=='Democrat']\n",
    "author_df_r = author_df.loc[author_df['politic']=='Republican']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_d =generate_LDA_model(author_df_d['tweets_clean'])\n",
    "model_r =generate_LDA_model(author_df_r['tweets_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_topicsd = get_topic_features1(author_df_d, model_d)\n",
    "author_topicsr = get_topic_features1(author_df_r, model_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.140773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.704582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.051924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.754004</td>\n",
       "      <td>0.164902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4    5        6         7  \\\n",
       "0  0.00000  0.000000  0.772162  0.140773  0.000000  0.0  0.00000  0.052060   \n",
       "1  0.00000  0.000000  0.850000  0.000000  0.000000  0.0  0.00000  0.000000   \n",
       "2  0.84568  0.000000  0.000000  0.000000  0.000000  0.0  0.09717  0.000000   \n",
       "3  0.00000  0.000000  0.233870  0.000000  0.704582  0.0  0.00000  0.000000   \n",
       "4  0.00000  0.051924  0.000000  0.000000  0.000000  0.0  0.00000  0.754004   \n",
       "\n",
       "          8    9  \n",
       "0  0.000000  0.0  \n",
       "1  0.088455  0.0  \n",
       "2  0.000000  0.0  \n",
       "3  0.000000  0.0  \n",
       "4  0.164902  0.0  "
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_probs(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    model= LogisticRegression()\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    probs = model.predict_proba(X_test)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-515-dd67dfd05c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "probs = get_probs(author_topicsd, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_two_probs(probs1, probs2):\n",
    "    \n",
    "    predicts = []\n",
    "    \n",
    "    for i in range(len(predicts)):\n",
    "        p0 = probs1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments = get_dataframe_sentiments(author_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66572"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_topics['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweets_raw</th>\n",
       "      <th>politics</th>\n",
       "      <th>tweets_clean</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'Touching &amp;amp; productive conversation w/ Fl...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Touching and productive conversation w  Florid...</td>\n",
       "      <td>[NeverAgain]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b\"Great news! Central FL's @OrangeCoSheriff aw...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Great news  Central FL s   awarded over  1 mil...</td>\n",
       "      <td>[Sayfie]</td>\n",
       "      <td>[OrangeCoSheriff, fema]</td>\n",
       "      <td>0.341667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'2016 Fla elections were subject to cyberatta...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>2016 Fla elections were subject to cyberattack...</td>\n",
       "      <td>[Sayfie]</td>\n",
       "      <td>[HispanicCaucus, HouseNewDems]</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'Enjoyed assembling snack packages with colle...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Enjoyed assembling snack packages with colleag...</td>\n",
       "      <td>[BeTheForce]</td>\n",
       "      <td>[the_USO]</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>b'Puerto Rico needs a long-term solution! CMS ...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Puerto Rico needs a long term solution  CMS mu...</td>\n",
       "      <td>[HurricaneSeason2018]</td>\n",
       "      <td>[Pwr4PuertoRico, HispanicCaucus, HispanicFed, ...</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                         tweets_raw  politics  \\\n",
       "0  RepDarrenSoto  b'Touching &amp; productive conversation w/ Fl...  Democrat   \n",
       "1  RepDarrenSoto  b\"Great news! Central FL's @OrangeCoSheriff aw...  Democrat   \n",
       "2  RepDarrenSoto  b'2016 Fla elections were subject to cyberatta...  Democrat   \n",
       "3  RepDarrenSoto  b'Enjoyed assembling snack packages with colle...  Democrat   \n",
       "4  RepDarrenSoto  b'Puerto Rico needs a long-term solution! CMS ...  Democrat   \n",
       "\n",
       "                                        tweets_clean               hashtags  \\\n",
       "0  Touching and productive conversation w  Florid...           [NeverAgain]   \n",
       "1  Great news  Central FL s   awarded over  1 mil...               [Sayfie]   \n",
       "2  2016 Fla elections were subject to cyberattack...               [Sayfie]   \n",
       "3  Enjoyed assembling snack packages with colleag...           [BeTheForce]   \n",
       "4  Puerto Rico needs a long term solution  CMS mu...  [HurricaneSeason2018]   \n",
       "\n",
       "                                            mentions  sentiment  \n",
       "0                                                 []   0.233333  \n",
       "1                            [OrangeCoSheriff, fema]   0.341667  \n",
       "2                     [HispanicCaucus, HouseNewDems]  -0.083333  \n",
       "3                                          [the_USO]   0.350000  \n",
       "4  [Pwr4PuertoRico, HispanicCaucus, HispanicFed, ...   0.225000  "
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mentions = find_mentions(author_df)\n",
    "\n",
    "author_df['mentions'] = mentions\n",
    "mm = mentionMatrix(author_df)\n",
    "\n",
    "df_final = author_topics.join(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_mentions(df):\n",
    "    \n",
    "    merged_mentions = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        mm = ' '.join(row['mentions'])\n",
    "        \n",
    "        merged_mentions.append(mm)\n",
    "        \n",
    "    \n",
    "    return merged_mentions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mmentions = merge_mentions(author_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_df['mmentions'] = mmentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_final\n",
    "y = author_df['politic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488372093023255"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 147)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIPAC</th>\n",
       "      <th>AjitPaiFCC</th>\n",
       "      <th>BarackObama</th>\n",
       "      <th>BetsyDeVosED</th>\n",
       "      <th>CDCgov</th>\n",
       "      <th>CFPB</th>\n",
       "      <th>CNN</th>\n",
       "      <th>ConawayTX11</th>\n",
       "      <th>CongressionalAC</th>\n",
       "      <th>DHSgov</th>\n",
       "      <th>...</th>\n",
       "      <th>realdonaldtrump</th>\n",
       "      <th>rep_stevewomack</th>\n",
       "      <th>repjohnlewis</th>\n",
       "      <th>the_USO</th>\n",
       "      <th>thehill</th>\n",
       "      <th>usairforce</th>\n",
       "      <th>uscapitol</th>\n",
       "      <th>usedgov</th>\n",
       "      <th>virginiafoxx</th>\n",
       "      <th>washingtonpost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AIPAC  AjitPaiFCC  BarackObama  BetsyDeVosED  CDCgov  CFPB  CNN  \\\n",
       "0     36          43           40            74      30    55   68   \n",
       "\n",
       "   ConawayTX11  CongressionalAC  DHSgov       ...        realdonaldtrump  \\\n",
       "0           30               48      74       ...                    106   \n",
       "\n",
       "   rep_stevewomack  repjohnlewis  the_USO  thehill  usairforce  uscapitol  \\\n",
       "0               30            49       59       55          32         85   \n",
       "\n",
       "   usedgov  virginiafoxx  washingtonpost  \n",
       "0       47            34              33  \n",
       "\n",
       "[1 rows x 137 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_columns = mdf3.columns[mdf3.ix[mdf3.last_valid_index()].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SenJohnMcCain</th>\n",
       "      <th>RepMarkMeadows</th>\n",
       "      <th>dcexaminer</th>\n",
       "      <th>ConawayTX11</th>\n",
       "      <th>Google</th>\n",
       "      <th>mail</th>\n",
       "      <th>rep_stevewomack</th>\n",
       "      <th>CDCgov</th>\n",
       "      <th>USArmyReserve</th>\n",
       "      <th>EPAoig</th>\n",
       "      <th>...</th>\n",
       "      <th>FCC</th>\n",
       "      <th>FoxBusiness</th>\n",
       "      <th>EPA</th>\n",
       "      <th>HouseCommerce</th>\n",
       "      <th>FoxNews</th>\n",
       "      <th>EPAScottPruitt</th>\n",
       "      <th>SpeakerRyan</th>\n",
       "      <th>HouseGOP</th>\n",
       "      <th>POTUS</th>\n",
       "      <th>realDonaldTrump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>178</td>\n",
       "      <td>202</td>\n",
       "      <td>214</td>\n",
       "      <td>232</td>\n",
       "      <td>295</td>\n",
       "      <td>488</td>\n",
       "      <td>589</td>\n",
       "      <td>1166</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SenJohnMcCain  RepMarkMeadows  dcexaminer  ConawayTX11  Google  mail  \\\n",
       "0             30              30          30           30      30    30   \n",
       "\n",
       "   rep_stevewomack  CDCgov  USArmyReserve  EPAoig       ...         FCC  \\\n",
       "0               30      30             31      31       ...         168   \n",
       "\n",
       "   FoxBusiness  EPA  HouseCommerce  FoxNews  EPAScottPruitt  SpeakerRyan  \\\n",
       "0          178  202            214      232             295          488   \n",
       "\n",
       "   HouseGOP  POTUS  realDonaldTrump  \n",
       "0       589   1166             1180  \n",
       "\n",
       "[1 rows x 137 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf3[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_matrix = pd.DataFrame(0, index = mdf3.columns, columns = mdf3.columns, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIPAC</th>\n",
       "      <th>AjitPaiFCC</th>\n",
       "      <th>BarackObama</th>\n",
       "      <th>BetsyDeVosED</th>\n",
       "      <th>CDCgov</th>\n",
       "      <th>CFPB</th>\n",
       "      <th>CNN</th>\n",
       "      <th>ConawayTX11</th>\n",
       "      <th>CongressionalAC</th>\n",
       "      <th>DHSgov</th>\n",
       "      <th>...</th>\n",
       "      <th>realdonaldtrump</th>\n",
       "      <th>rep_stevewomack</th>\n",
       "      <th>repjohnlewis</th>\n",
       "      <th>the_USO</th>\n",
       "      <th>thehill</th>\n",
       "      <th>usairforce</th>\n",
       "      <th>uscapitol</th>\n",
       "      <th>usedgov</th>\n",
       "      <th>virginiafoxx</th>\n",
       "      <th>washingtonpost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AIPAC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AjitPaiFCC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BarackObama</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BetsyDeVosED</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDCgov</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AIPAC  AjitPaiFCC  BarackObama  BetsyDeVosED  CDCgov  CFPB  CNN  \\\n",
       "AIPAC             0           0            0             0       0     0    0   \n",
       "AjitPaiFCC        0           0            0             0       0     0    0   \n",
       "BarackObama       0           0            0             0       0     0    0   \n",
       "BetsyDeVosED      0           0            0             0       0     0    0   \n",
       "CDCgov            0           0            0             0       0     0    0   \n",
       "\n",
       "              ConawayTX11  CongressionalAC  DHSgov       ...        \\\n",
       "AIPAC                   0                0       0       ...         \n",
       "AjitPaiFCC              0                0       0       ...         \n",
       "BarackObama             0                0       0       ...         \n",
       "BetsyDeVosED            0                0       0       ...         \n",
       "CDCgov                  0                0       0       ...         \n",
       "\n",
       "              realdonaldtrump  rep_stevewomack  repjohnlewis  the_USO  \\\n",
       "AIPAC                       0                0             0        0   \n",
       "AjitPaiFCC                  0                0             0        0   \n",
       "BarackObama                 0                0             0        0   \n",
       "BetsyDeVosED                0                0             0        0   \n",
       "CDCgov                      0                0             0        0   \n",
       "\n",
       "              thehill  usairforce  uscapitol  usedgov  virginiafoxx  \\\n",
       "AIPAC               0           0          0        0             0   \n",
       "AjitPaiFCC          0           0          0        0             0   \n",
       "BarackObama         0           0          0        0             0   \n",
       "BetsyDeVosED        0           0          0        0             0   \n",
       "CDCgov              0           0          0        0             0   \n",
       "\n",
       "              washingtonpost  \n",
       "AIPAC                      0  \n",
       "AjitPaiFCC                 0  \n",
       "BarackObama                0  \n",
       "BetsyDeVosED               0  \n",
       "CDCgov                     0  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_matrix['AIPAC']['CDCgov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37066400051116943"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_topics[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hashtag_sentiment(hashtag, df):\n",
    "    \n",
    "    s = [0]*df.shape[0]\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    current = ''\n",
    "    \n",
    "    i = 0 \n",
    "    \n",
    "    while i < df.shape[0]:\n",
    "        \n",
    "        if hashtag in df['mentions'][i]:\n",
    "            \n",
    "            if df['username'][i] != current:\n",
    "                current = df['mentions'][i]\n",
    "                \n",
    "                s.append(get_sentiment(df['tweets_clean'][i]))\n",
    "            \n",
    "            else:\n",
    "                s[len(s) - 1] += get_sentiment(df['tweets_clean'][i])\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return s\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hashtag_sentiment(hashtag, df):\n",
    "    \n",
    "    current = ''\n",
    "    s = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i < df.shape[0]:\n",
    "        \n",
    "        if df['username'][i] != current:\n",
    "            s.append(0)\n",
    "            \n",
    "            current = df['username'][i]\n",
    "            \n",
    "        if hashtag in df['mentions'][i]:\n",
    "            \n",
    "            s[len(s) - 1] += get_sentiment(df['tweets_clean'][i])[0]\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return s\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = get_hashtag_sentiment('realDonaldTrump', tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_topics['rdt_sentiment'] = st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "def cc_matrix(wordlist):\n",
    "    \n",
    "    samples = wordlist\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), vocabulary = {'awesome unicorns':0, 'batman forever':1}) \n",
    "    co_occurrences = bigram_vectorizer.fit_transform(samples)\n",
    "    print('Printing sparse matrix:' + str(co_occurrences))\n",
    "    print('Printing dense matrix (cols are vocabulary keys 0-> \"awesome unicorns\", 1-> \"batman forever\")' +str(co_occurrences.todense()))\n",
    "    sum_occ = np.sum(co_occurrences.todense(),axis=0)\n",
    "    print ('Sum of word-word occurrences:' + str(sum_occ))\n",
    "    print ('Pretty printig of co_occurrences count:', zip(bigram_vectorizer.get_feature_names(),np.array(sum_occ)[0].tolist()))\n",
    "\n",
    "    \n",
    "#cc_matrix(author_df['mmentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = author_topics\n",
    "y = author_df['politic']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6355140186915887"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
